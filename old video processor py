import os
import moviepy.config as mpy_config
mpy_config.change_settings({"IMAGEMAGICK_BINARY": r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe"})
from moviepy.editor import (TextClip, ImageClip, VideoFileClip, CompositeVideoClip,
                            concatenate_videoclips, AudioFileClip, ColorClip)
from utils.config_loader import load_config
from Content_Engine import media_fetcher
import logging

# Setup logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
                    filename='./logs/video_processor.log')
logger = logging.getLogger('video_processor')

# Ensure ImageMagick is correctly set up
if os.name == 'nt':
    os.environ["IMAGEMAGICK_BINARY"] = r"C:\Program Files\ImageMagick-7.1.1-Q16-HDRI\magick.exe"


class VideoProcessor:
    def __init__(self, config=None):
        self.config = config if config else load_config()
        self.media_fetcher = media_fetcher.MediaFetcher(self.config)
        self.resolution = (
            self.config['media']['resolution']['width'],
            self.config['media']['resolution']['height']
        )
        self.font = self.config['video_style']['font']
        self.font_size = self.config['video_style']['font_size']
        self.font_color = self.config['video_style']['font_color']
        self.text_position = self.config['video_style']['text_position']
        self.transition = self.config['video_style']['transition']
        self.transition_duration = self.config['video_style']['transition_duration']

    def create_scene_clip(self, scene_text, duration, keywords=None):
        """Create an improved video clip for a scene with dynamic text and background."""
        if not keywords:
            keywords = self.media_fetcher.extract_keywords_from_text(scene_text)

        # Get background media
        bg_media_path = self.media_fetcher.fetch_media_for_keywords(keywords, "image")

        # If no image found, use a gradient color background
        if not bg_media_path:
            logger.warning("No background found. Using a dynamic gradient background.")
            bg_clip = ColorClip(size=self.resolution, color=(30, 30, 30), duration=duration)
        else:
            if bg_media_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
                bg_clip = ImageClip(bg_media_path).set_duration(duration)
            else:
                bg_clip = VideoFileClip(bg_media_path).subclip(0, duration)

            # Resize background media
            bg_clip = bg_clip.resize(height=self.resolution[1])
            if bg_clip.w > self.resolution[0]:
                x_start = (bg_clip.w - self.resolution[0]) // 2
                bg_clip = bg_clip.crop(x1=x_start, width=self.resolution[0])

        # Dynamic font size based on text length
        adjusted_font_size = max(self.font_size - len(scene_text) // 10, 20)

        # Create text overlay with shadow
        text_clip = TextClip(
            scene_text,
            fontsize=adjusted_font_size,
            color=self.font_color,
            font=self.font,
            method='caption',
            size=(self.resolution[0] * 0.8, None),
            stroke_width=2,
            stroke_color="black"
        ).set_duration(duration)

        # Text positioning
        text_position = {
            'center': 'center',
            'bottom': ('center', self.resolution[1] - adjusted_font_size * 2),
            'top': ('center', adjusted_font_size),
        }.get(self.text_position, 'center')

        text_clip = text_clip.set_position(text_position)

        # Apply fade-in/out effect
        text_clip = text_clip.fadein(0.5).fadeout(0.5)
        bg_clip = bg_clip.fadein(0.5).fadeout(0.5)

        # Combine clips
        return CompositeVideoClip([bg_clip, text_clip])

    def process_video(self, scenes, voice_file=None):
        """Process full video with transitions and audio."""
        clips = []
        for i, scene in enumerate(scenes):
            duration = max(len(scene.split()) * 0.5, self.config['scene']['min_duration'])
            duration = min(duration, self.config['scene']['max_duration'])

            clip = self.create_scene_clip(scene, duration)

            if i > 0 and self.transition == 'fade':
                clip = clip.crossfadein(self.transition_duration)

            clips.append(clip)

        # Merge all scene clips
        final_video = concatenate_videoclips(clips, method="compose")

        # Add audio if provided
        if voice_file and os.path.exists(voice_file):
            audio = AudioFileClip(voice_file)
            final_video = final_video.set_audio(audio)

            if audio.duration > final_video.duration:
                logger.info(f"Extending video duration to match audio ({audio.duration}s).")
                final_video = final_video.set_duration(audio.duration)

        # Save final video
        output_dir = self.config['project']['output_dir']
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, "final_video.mp4")

        final_video.write_videofile(output_path, codec="libx264", fps=self.config['media']['fps'])
        return output_path
